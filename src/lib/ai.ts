import { generateObject, generateText } from "ai";
import { openai } from "@ai-sdk/openai";
import { z } from "zod";
import { Project, ProjectMetrics } from "./interfaces";
import { cache } from "react";

const projectSchema = z.object({
  usesVercel: z.boolean(),
  isDeployed: z.boolean(),
  name: z.string(),
  projectName: z.string(),
  projectDescription: z.string(),
  repoUrl: z.string(),
  projectUrl: z.string(),
  instructions: z.string(),
});

export const generateProjectJSON = cache(
  async (rawProject: string): Promise<Project> => {
    const { object } = await generateObject({
      model: openai("gpt-4o-mini"),
      schema: projectSchema,
      prompt: `Extra√© del siguiente texto la informaci√≥n relevante al proyecto, seg√∫n el esquema JSON que te proporciono. Deber√°s extraer la informaci√≥n en formato JSON. Elimin√° de la respuesta cualquier \n o \r que encuentres en el texto original.
    
    Ejemplo del texto:
    "### Se√±ala los requisitos cumplidos.\r\n\r\n- [x] Mi aplicaci√≥n usa Vercel SDK AI de alguna forma.\r\n- [ ] Mi aplicaci√≥n est√° desplegada y funciona\r\n\r\n\r\n### Escribe tu nombre o el del equipo\r\n\r\nDevJL\r\n\r\n### Nombre del proyecto\r\n\r\nminicue\r\n\r\n### Descripci√≥n del proyecto\r\n\r\nMi proyecto es un generador de guiones literarios b√°sico para videos de formato corto, en este caso para Tiktok.\r\n\r\nhttps://github.com/user-attachments/assets/47e2b1d7-03c5-4b13-a5e8-f162940a3df1\r\n\r\n## ¬øC√≥mo funciona? ‚öôÔ∏è\r\n\r\nPor medio de 3 par√°metros, como se ve en el video de demostraci√≥n, que son el tema, la duraci√≥n del video y el idioma que elija, el usuario tendr√° su gui√≥n en menos de 1 minuto; tambi√©n tiene funcionalidad de copiar el c√≥digo como de limpiar los campos del formulario como del resultado. \r\n\r\n## ¬øQu√© utiliza?üõ†Ô∏è\r\n\r\n- Sveltekit\r\n- Tailwind CSS\r\n- Vercel AI SDK\r\n- Groq modelo 'llama3-8b-8192' (solo est√° limitado a 8k de tokens)\r\n\r\n### Limitaciones\r\n\r\nComo se menciona, el modelo que estoy usando es parte de Groq y tiene un n√∫mero de tokens limitado a 8k por d√≠a; si se agotan los tokens no se puede volver a utilizar hasta el d√≠a siguiente.\r\n\r\nEl c√≥digo se puede mejorar, ya que es la primera vez que uso Sveltekit, ya que solo he trabajado con astro y react y cualquier cr√≠tica o retroalimentaci√≥n ser√° recibida.\r\n\r\n### Repositorio de c√≥digo\r\n\r\nhttps://github.com/devjhonluna/minicue\r\n\r\n### Proyecto desplegado\r\n\r\nhttps://minicue.netlify.app/\r\n\r\n### Instrucciones de configuraci√≥n\r\n\r\nPuedes instalar el proyecto con las instrucciones del Readme [üìñ](https://github.com/devjhonluna/minicue?tab=readme-ov-file#ejecuci√≥n-local)."

    Ejemplo de respuesta:
    {
      "usesVercel": true,
      "isDeployed": false,
      "name": "DevJL",
      "projectName": "minicue",
      "projectDescription": "Mi proyecto es un generador de guiones literarios b√°sico para videos de formato corto, en este caso para Tiktok. https://github.com/user-attachments/assets/47e2b1d7-03c5-4b13-a5e8-f162940a3df1 ## ¬øC√≥mo funciona? ‚öôÔ∏è Por medio de 3 par√°metros, como se ve en el video de demostraci√≥n, que son el tema, la duraci√≥n del video y el idioma que elija, el usuario tendr√° su gui√≥n en menos de 1 minuto; tambi√©n tiene funcionalidad de copiar el c√≥digo como de limpiar los campos del formulario como del resultado. ## ¬øQu√© utiliza?üõ†Ô∏è - Sveltekit - Tailwind CSS - Vercel AI SDK - Groq modelo 'llama3-8b-8192' (solo est√° limitado a 8k de tokens) ### Limitaciones\r\n\r\nComo se menciona, el modelo que estoy usando es parte de Groq y tiene un n√∫mero de tokens limitado a 8k por d√≠a; si se agotan los tokens no se puede volver a utilizar hasta el d√≠a siguiente. El c√≥digo se puede mejorar, ya que es la primera vez que uso Sveltekit, ya que solo he trabajado con astro y react y cualquier cr√≠tica o retroalimentaci√≥n ser√° recibida.",
      "repoUrl": "https://github.com/devjhonluna/minicue",
      "projectUrl": "https://minicue.netlify.app/",
      "instructions": "Puedes instalar el proyecto con las instrucciones del Readme [üìñ](https://github.com/devjhonluna/minicue?tab=readme-ov-file#ejecuci√≥n-local)."
    }

    Texto:
    ${rawProject}
    `,
    });

    return object;
  }
);

export const generateMetricsResume = cache(
  async ({
    totalProjects,
    fullyCompliantCount,
    nonCompliantCount,
    onlyDeployedCount,
    onlyVercelSDKCount,
  }: ProjectMetrics): Promise<string> => {
    const { text } = await generateText({
      model: openai("gpt-4o-mini"),
      prompt: `Vercel ha lanzado una hackat√≥n de proyectos para que usen Vercel SDK AI, un nuevo paquete.
      Los proyectos tienen 2 requisitos para participar. Deben usar Vercel SDK AI de alguna forma. Y pueden estar desplegados y funcionales.
      El √∫nico requisito obligatorio es usar Vercel SDK AI.

      Se recolectaron estas m√©tricas de los proyectos que participan:
      Total de proyectos: ${totalProjects}
      Cantidad de proyectos que cumplen los 2 requisitos: ${fullyCompliantCount}
      Cantidad de proyectos que solo usan Vercel SDK AI: ${onlyVercelSDKCount}
      Cantidad de proyectos que solo est√°n deployados: ${onlyDeployedCount}
      Cantidad de proyectos que no cumplen ningun requisito: ${nonCompliantCount}

      Basandote en esa informaci√≥n, gener√° y devolv√© un texto a modo de resumen que pueda concluir una idea teniendo en cuenta esas m√©tricas.
      El texto generado tiene que tener un m√°ximo de 1 oraci√≥n. Debe ser breve y no contener informaci√≥n redundante. No deb√©s incluir los n√∫meros de las m√©tricas, ya que estar√°n mostrados en un gr√°fico de torta. 
      El texto generado debe funcionar como descripci√≥n al gr√°fico de torta.
      El texto debe concluir una idea basandose en los datos, no tiene que describirlos.
      `,
    });
    return text;
  }
);
